{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d797e5da",
   "metadata": {},
   "source": [
    "# Multi-Dataset Bankruptcy Prediction — Full Pipeline\n",
    "\n",
    "This notebook implements the full project specification. It includes:\n",
    "\n",
    "1. Data ingestion (ARFF + CSVs) and annotation (`dataset_source`, `horizon_years`).\n",
    "2. EDA (class ratios, missingness, distributions, correlations, PCA, per-dataset plots).\n",
    "3. Safe splitting (group-aware when possible) and saving split sizes.\n",
    "4. Robust preprocessing (median numeric impute, categorical string-cast, constant impute or most-frequent, dataset_source one-hot), with feature-name mapping for feature importances.\n",
    "5. Baselines (Logistic Regression, Decision Tree) with per-dataset evaluation.\n",
    "6. CV comparison: LightGBM (class-weight) vs LightGBM (SMOTE) with early stopping, preproc fit inside folds, SMOTE only on training fold.\n",
    "7. Final model training with internal validation for early stopping, calibration (Platt), threshold tuning (accuracy subject to recall >= 0.6), and final test evaluation.\n",
    "8. Feature importance mapping and SHAP analysis.\n",
    "9. Saving artifacts: preproc, model, calibrated object, threshold, and a picklable `BankruptcyModel` wrapper with `predict`/`predict_proba`.\n",
    "10. Reproducibility: `requirements_full.txt`, `requirements_min.txt`, and runbook.\n",
    "11. Diagnostics & leakage checks, adversarial validation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "de5813c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python 3.12.9 | packaged by Anaconda, Inc. | (main, Feb  6 2025, 18:49:16) [MSC v.1929 64 bit (AMD64)]\n",
      "pandas 2.2.3 numpy 2.2.6 lightgbm 4.6.0\n",
      "BASE_DIR: bankruptcy_prediction_data\n",
      "OUT_DIR: bankruptcy_outputs\n"
     ]
    }
   ],
   "source": [
    "# 0. Setup: imports, paths, seeds\n",
    "import sys, os, random, warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "import numpy as np; np.random.seed(SEED)\n",
    "import pandas as pd, matplotlib.pyplot as plt, seaborn as sns\n",
    "import joblib, json, re, subprocess, traceback\n",
    "from pathlib import Path\n",
    "\n",
    "# sklearn / imblearn\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, GroupShuffleSplit\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OrdinalEncoder, OneHotEncoder, FunctionTransformer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.metrics import (roc_auc_score, average_precision_score, accuracy_score, f1_score,\n",
    "                             precision_score, recall_score, confusion_matrix, roc_curve, precision_recall_curve)\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "\n",
    "# Paths\n",
    "BASE_DIR = \"bankruptcy_prediction_data\"\n",
    "OUT_DIR = \"bankruptcy_outputs\"\n",
    "EDA_DIR = os.path.join(OUT_DIR, 'eda')\n",
    "MODELS_DIR = os.path.join(OUT_DIR, 'models')\n",
    "REPORTS_DIR = os.path.join(OUT_DIR, 'reports')\n",
    "DATA_DIR = os.path.join(OUT_DIR, 'data')\n",
    "for d in [OUT_DIR, EDA_DIR, MODELS_DIR, REPORTS_DIR, DATA_DIR]:\n",
    "    os.makedirs(d, exist_ok=True)\n",
    "\n",
    "print('python', sys.version)\n",
    "print('pandas', pd.__version__, 'numpy', np.__version__, 'lightgbm', lgb.__version__)\n",
    "print('BASE_DIR:', BASE_DIR)\n",
    "print('OUT_DIR:', OUT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ad612270",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading bankruptcy_prediction_data\\1year.arff\n",
      "Reading bankruptcy_prediction_data\\2year.arff\n",
      "Reading bankruptcy_prediction_data\\3year.arff\n",
      "Reading bankruptcy_prediction_data\\4year.arff\n",
      "Reading bankruptcy_prediction_data\\5year.arff\n",
      "Poland shape: (43405, 68)\n",
      "Taiwan shape: (6819, 99)\n",
      "American shape: (78682, 24)\n",
      "Combined shape: (128906, 185)\n",
      "Saved combined_raw.csv\n"
     ]
    }
   ],
   "source": [
    "# 1. Data ingestion: ARFF parser + CSVs, annotate dataset_source and horizon_years\n",
    "from io import StringIO\n",
    "\n",
    "def read_arff(path):\n",
    "    txt = open(path, 'r', encoding='utf-8', errors='ignore').read()\n",
    "    if '@data' not in txt.lower():\n",
    "        raise ValueError(f'No @data section found in {path}')\n",
    "    header, data = re.split('@data', txt, flags=re.IGNORECASE, maxsplit=1)\n",
    "    attrs = []\n",
    "    for line in header.splitlines():\n",
    "        line = line.strip()\n",
    "        if line.lower().startswith('@attribute'):\n",
    "            # try different patterns\n",
    "            m = re.match(r\"@attribute\\s+'?\\\"?([^'\\\"]+)'?\\\"?\\s+(.*)\", line, flags=re.IGNORECASE)\n",
    "            if not m:\n",
    "                m = re.match(r\"@attribute\\s+([^\\s]+)\\s+(.*)\", line, flags=re.IGNORECASE)\n",
    "            if m:\n",
    "                attrs.append(m.group(1).strip())\n",
    "    data_lines = [ln.strip() for ln in data.splitlines() if ln.strip() and not ln.strip().startswith('%')]\n",
    "    df = pd.read_csv(StringIO('\\n'.join(data_lines)), header=None, names=attrs)\n",
    "    return df\n",
    "\n",
    "# Load Poland horizons (1-5 years)\n",
    "poland_files = ['1year.arff','2year.arff','3year.arff','4year.arff','5year.arff']\n",
    "poland_dfs = []\n",
    "for i, fname in enumerate(poland_files, start=1):\n",
    "    p = os.path.join(BASE_DIR, fname)\n",
    "    if not os.path.exists(p):\n",
    "        print('Poland file not found:', p, ' — skipping. Ensure your BASE_DIR is correct.')\n",
    "        continue\n",
    "    print('Reading', p)\n",
    "    df = read_arff(p)\n",
    "    df['dataset_source'] = 'poland'\n",
    "    df['horizon_years'] = i\n",
    "    # try to detect class column\n",
    "    if 'class' in df.columns:\n",
    "        try:\n",
    "            df['y'] = df['class'].astype(int)\n",
    "        except Exception:\n",
    "            # map possible labels\n",
    "            df['y'] = df['class'].astype(str).str.strip().map({'1':1,'0':0,'yes':1,'no':0,'bankrupt':1}).fillna(0).astype(int)\n",
    "    poland_dfs.append(df)\n",
    "if poland_dfs:\n",
    "    poland = pd.concat(poland_dfs, ignore_index=True, sort=False)\n",
    "    print('Poland shape:', poland.shape)\n",
    "else:\n",
    "    poland = pd.DataFrame(); print('No Poland data loaded.')\n",
    "\n",
    "# Taiwan\n",
    "tai_path = os.path.join(BASE_DIR, 'taiwan_bankruptcy.csv')\n",
    "tai = pd.DataFrame()\n",
    "if os.path.exists(tai_path):\n",
    "    tai = pd.read_csv(tai_path)\n",
    "    tai.columns = tai.columns.str.strip().str.replace('\\n',' ').str.replace('[^0-9A-Za-z_ ]','_', regex=True)\n",
    "    tai['dataset_source'] = 'taiwan'; tai['horizon_years'] = 1\n",
    "    bank_cols = [c for c in tai.columns if 'bankrupt' in c.lower() or 'bankrupt?' in c.lower() or 'bankruptcy' in c.lower() or 'bankrupt_' in c.lower()]\n",
    "    if len(bank_cols)==0:\n",
    "        # attempt common column names\n",
    "        for cand in ['Bankrupt?','Bankrupt','bankrupt','Bankrupt_','bankrupt?','bankrupt_label']:\n",
    "            if cand in tai.columns:\n",
    "                bank_cols.append(cand)\n",
    "    if len(bank_cols)==0:\n",
    "        print('WARNING: No bankrupt-style column found in tai CSV; available columns:', tai.columns[:30])\n",
    "    else:\n",
    "        tai['y'] = tai[bank_cols[0]].astype(str).str.strip().replace({'0':'0','1':'1'}).astype(int)\n",
    "    print('Taiwan shape:', tai.shape)\n",
    "else:\n",
    "    print('Taiwan CSV not found at', tai_path)\n",
    "\n",
    "# US (american)\n",
    "amer_path = os.path.join(BASE_DIR, 'american_bankruptcy.csv')\n",
    "amer = pd.DataFrame()\n",
    "if os.path.exists(amer_path):\n",
    "    amer = pd.read_csv(amer_path)\n",
    "    amer.columns = amer.columns.str.strip().str.replace('[^0-9A-Za-z_ ]','_', regex=True)\n",
    "    amer['dataset_source'] = 'us'; amer['horizon_years'] = 1\n",
    "    if 'status_label' in amer.columns:\n",
    "        amer['y'] = (amer['status_label'].astype(str).str.lower()=='failed').astype(int)\n",
    "    else:\n",
    "        cand = [c for c in amer.columns if 'status' in c.lower() or 'label' in c.lower()]\n",
    "        if cand:\n",
    "            print('Using', cand[0], 'as status label')\n",
    "            amer['y'] = (amer[cand[0]].astype(str).str.lower()=='failed').astype(int)\n",
    "        else:\n",
    "            print('WARNING: No status_label found in american CSV; columns:', amer.columns[:30])\n",
    "    print('American shape:', amer.shape)\n",
    "else:\n",
    "    print('American CSV not found at', amer_path)\n",
    "\n",
    "# Combine (union — keep native columns, missing columns will be NaN)\n",
    "combined = pd.concat([df for df in [amer, tai, poland] if not df.empty], ignore_index=True, sort=False)\n",
    "print('Combined shape:', combined.shape)\n",
    "combined.to_csv(os.path.join(DATA_DIR, 'combined_raw.csv'), index=False)\n",
    "print('Saved combined_raw.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d6f26bb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "us rows: 78682, positives: 5220, rate: 0.066343\n",
      "taiwan rows: 6819, positives: 220, rate: 0.032263\n",
      "poland rows: 43405, positives: 2091, rate: 0.048174\n",
      "Saved missingness_top50.csv\n",
      "Saved missingness_heatmap.png\n",
      "Saved numeric_describe.csv\n",
      "Saved sample distribution plots for features: ['X1', 'X2', 'X3', 'X4', 'X5', 'X6']\n",
      "Saved correlation_heatmap.png\n",
      "Saved class_means.csv\n",
      "Saved dataset-shift boxplots\n",
      "Saved pca_sample.png\n"
     ]
    }
   ],
   "source": [
    "# 2. Extended EDA: class ratios, missingness, descriptive stats, distributions, correlations, PCA\n",
    "os.makedirs(EDA_DIR, exist_ok=True)\n",
    "\n",
    "# Class ratios per dataset\n",
    "for src in combined['dataset_source'].unique():\n",
    "    tmp = combined[combined['dataset_source']==src]\n",
    "    rate = tmp['y'].mean() if 'y' in tmp.columns else 0\n",
    "    print(f\"{src} rows: {len(tmp)}, positives: {int(tmp.get('y',0).sum())}, rate: {round(rate,6)}\")\n",
    "\n",
    "# Missingness\n",
    "miss = combined.isnull().mean().sort_values(ascending=False)\n",
    "miss.head(50).to_csv(os.path.join(EDA_DIR, 'missingness_top50.csv'))\n",
    "print('Saved missingness_top50.csv')\n",
    "\n",
    "# Missingness heatmap (sample)\n",
    "plt.figure(figsize=(12,3))\n",
    "sns.heatmap(combined.sample(min(1000, len(combined)), random_state=SEED).isnull(), cbar=False)\n",
    "plt.title('Missingness (sample up to 1000 rows)')\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(EDA_DIR, 'missingness_heatmap.png'))\n",
    "plt.close()\n",
    "print('Saved missingness_heatmap.png')\n",
    "\n",
    "# Numeric descriptive stats\n",
    "num_cols = combined.select_dtypes(include=[np.number]).columns.tolist()\n",
    "num_desc = combined[num_cols].describe().T\n",
    "num_desc.to_csv(os.path.join(EDA_DIR, 'numeric_describe.csv'))\n",
    "print('Saved numeric_describe.csv')\n",
    "\n",
    "# Numeric distributions (up to 6 features)\n",
    "numeric_cols = combined.select_dtypes(include=['number']).columns.tolist()\n",
    "sample_features = numeric_cols[1:7] if len(numeric_cols)>7 else numeric_cols[:6]\n",
    "for col in sample_features:\n",
    "    plt.figure(figsize=(6,3))\n",
    "    try:\n",
    "        sns.kdeplot(data=combined, x=col, hue='y', common_norm=False, fill=True, alpha=0.3)\n",
    "    except Exception:\n",
    "        sns.histplot(data=combined, x=col, hue='y', element='step', stat='density', common_norm=False)\n",
    "    plt.title(f'Distribution of {col} by target')\n",
    "    plt.tight_layout()\n",
    "    fname = os.path.join(EDA_DIR, f'dist_{col}.png')\n",
    "    plt.savefig(fname); plt.close()\n",
    "print('Saved sample distribution plots for features:', sample_features)\n",
    "\n",
    "# Correlation heatmap\n",
    "corr = combined.select_dtypes(include=['number']).corr()\n",
    "plt.figure(figsize=(10,8))\n",
    "sns.heatmap(corr, cmap='coolwarm', center=0)\n",
    "plt.title('Correlation heatmap (numeric)')\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(EDA_DIR, 'correlation_heatmap.png')); plt.close()\n",
    "print('Saved correlation_heatmap.png')\n",
    "\n",
    "# Class-conditional means\n",
    "if 'y' in combined.columns:\n",
    "    class_means = combined[num_cols].groupby(combined['y']).mean().T\n",
    "    class_means.to_csv(os.path.join(EDA_DIR, 'class_means.csv'))\n",
    "    print('Saved class_means.csv')\n",
    "\n",
    "# Dataset shifts for sample features\n",
    "for col in sample_features:\n",
    "    plt.figure(figsize=(6,3))\n",
    "    sns.boxplot(data=combined, x='dataset_source', y=col)\n",
    "    plt.title(f'{col} by dataset_source')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(EDA_DIR, f'box_{col}_by_dataset.png')); plt.close()\n",
    "print('Saved dataset-shift boxplots')\n",
    "\n",
    "# PCA on numeric features (sampled)\n",
    "X_num = combined.select_dtypes(include='number').fillna(0)\n",
    "n_sample = min(2000, X_num.shape[0])\n",
    "X_sample = X_num.sample(n_sample, random_state=SEED)\n",
    "y_sample = combined.loc[X_sample.index, 'y']\n",
    "pca = PCA(n_components=2, random_state=SEED)\n",
    "X_pca = pca.fit_transform(X_sample)\n",
    "plt.figure(figsize=(6,5))\n",
    "plt.scatter(X_pca[:,0], X_pca[:,1], c=y_sample, cmap='coolwarm', alpha=0.5, s=8)\n",
    "plt.title('PCA (sample) colored by bankruptcy'); plt.tight_layout()\n",
    "plt.savefig(os.path.join(EDA_DIR, 'pca_sample.png')); plt.close()\n",
    "print('Saved pca_sample.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "928a2729",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected group column (if any): None\n",
      "Train_df shape: (103124, 185) Test_df shape: (25782, 185)\n",
      "Saved split_sizes.json\n"
     ]
    }
   ],
   "source": [
    "# 3. Data splitting strategy per spec: Stratified 80/20 per dataset (with group-aware option)\n",
    "# We'll detect a likely group id (firm/company) to prevent horizon leakage in Poland.\n",
    "possible_group_cols = [c for c in combined.columns if c.lower() in ('firm_id','company','id','ticker','name','company_id','firm')]\n",
    "group_col = possible_group_cols[0] if possible_group_cols else None\n",
    "print('Detected group column (if any):', group_col)\n",
    "\n",
    "train_parts = []\n",
    "test_parts = []\n",
    "for src in combined['dataset_source'].unique():\n",
    "    df_src = combined[combined['dataset_source']==src].copy().reset_index(drop=True)\n",
    "    if group_col and group_col in df_src.columns:\n",
    "        # group-aware split: ensure groups are not shared across train/test\n",
    "        gss = GroupShuffleSplit(n_splits=1, test_size=0.2, random_state=SEED)\n",
    "        try:\n",
    "            tr_idx, te_idx = next(gss.split(df_src, groups=df_src[group_col]))\n",
    "        except Exception as e:\n",
    "            print('Group split failed for', src, e); tr_idx, te_idx = train_test_split(df_src.index, test_size=0.2, stratify=df_src['y'] if 'y' in df_src else None, random_state=SEED)\n",
    "    else:\n",
    "        if 'y' in df_src.columns and df_src['y'].nunique()>1 and df_src.shape[0]>=10:\n",
    "            tr_idx, te_idx = train_test_split(df_src.index, test_size=0.2, stratify=df_src['y'], random_state=SEED)\n",
    "        else:\n",
    "            tr_idx, te_idx = train_test_split(df_src.index, test_size=0.2, random_state=SEED)\n",
    "    train_parts.append(df_src.loc[tr_idx])\n",
    "    test_parts.append(df_src.loc[te_idx])\n",
    "\n",
    "train_df = pd.concat(train_parts, ignore_index=True, sort=False)\n",
    "test_df  = pd.concat(test_parts,  ignore_index=True, sort=False)\n",
    "print('Train_df shape:', train_df.shape, 'Test_df shape:', test_df.shape)\n",
    "\n",
    "# Save split sizes\n",
    "sizes = {}\n",
    "for src in combined['dataset_source'].unique():\n",
    "    sizes[src] = {'total': int((combined['dataset_source']==src).sum()),\n",
    "                  'train': int((train_df['dataset_source']==src).sum()),\n",
    "                  'test': int((test_df['dataset_source']==src).sum()),\n",
    "                  'positives_total': int(((combined['dataset_source']==src) & (combined['y']==1)).sum()) if 'y' in combined.columns else None}\n",
    "with open(os.path.join(REPORTS_DIR, 'split_sizes.json'), 'w') as f:\n",
    "    json.dump(sizes, f, indent=2)\n",
    "print('Saved split_sizes.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "738cb1fe-d2ed-45f2-8da7-8f275ff6e083",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropping highly correlated numeric features: ['X9', 'X12', 'X16', 'X17', 'X18', 'Bankrupt_', 'ROA_B_ before interest and depreciation after tax', 'Realized Sales Gross Margin', 'After_tax net Interest Rate', 'Continuous interest rate _after tax_', 'Net Value Per Share _A_', 'Net Value Per Share _C_', 'Per Share Net profit before tax _Yuan __', 'Regular Net Profit Growth Rate', 'Net worth_Assets', 'Operating profit_Paid_in capital', 'Net profit before tax_Paid_in capital', 'Working capitcal Turnover Rate', 'Cash Flow to Sales', 'Current Liability to Liability', 'Current Liability to Equity', 'Net Income to Total Assets', 'Gross Profit to Sales', 'Liability to Equity', 'class']\n"
     ]
    }
   ],
   "source": [
    "# Collinearity pruning before preprocessing\n",
    "# Keep only numeric columns\n",
    "numeric_cols = train_df.select_dtypes(include=['number']).columns.tolist()\n",
    "\n",
    "# Compute correlation matrix\n",
    "corr_matrix = train_df[numeric_cols].corr().abs()\n",
    "\n",
    "# Upper triangle\n",
    "upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))\n",
    "\n",
    "# Drop highly correlated features (threshold = 0.95)\n",
    "to_drop = [col for col in upper.columns if any(upper[col] > 0.95)]\n",
    "print(\"Dropping highly correlated numeric features:\", to_drop)\n",
    "\n",
    "# Optionally drop from train/test\n",
    "train_df = train_df.drop(columns=to_drop)\n",
    "test_df  = test_df.drop(columns=to_drop, errors='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "6238a9a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numeric features: 92 Other cat features: 66\n"
     ]
    }
   ],
   "source": [
    "# 4. Preprocessing: preserve native features; one-hot dataset_source; median impute numerics within pipeline\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "\n",
    "# Identify numeric and categorical columns in train_df (excluding target)\n",
    "drop_cols = ['y']\n",
    "all_cols = [c for c in train_df.columns if c not in drop_cols]\n",
    "\n",
    "numeric_cols = train_df.select_dtypes(include=['number']).columns.tolist()\n",
    "numeric_cols = [c for c in numeric_cols if c != 'y']\n",
    "\n",
    "cat_cols = [c for c in all_cols if c not in numeric_cols and c!='dataset_source']\n",
    "\n",
    "# We'll one-hot encode dataset_source explicitly\n",
    "ohe_cols = ['dataset_source']\n",
    "\n",
    "# helper\n",
    "def to_str_func(X):\n",
    "    return X.astype(str)\n",
    "\n",
    "# numeric transformer (median)\n",
    "num_tf = Pipeline([('imputer', SimpleImputer(strategy='median'))])\n",
    "\n",
    "# safe OneHotEncoder fallback: use sparse_output if available else sparse\n",
    "ohe_params = {}\n",
    "try:\n",
    "    OneHotEncoder(sparse_output=False)\n",
    "    ohe_params['sparse_output'] = False\n",
    "except Exception:\n",
    "    ohe_params['sparse'] = False\n",
    "\n",
    "ohe_tf = Pipeline([('ohe', OneHotEncoder(handle_unknown='ignore', **ohe_params))])\n",
    "\n",
    "# categorical transformer: cast to str, impute constant 'missing', then ordinal\n",
    "cat_tf = Pipeline([\n",
    "    ('to_str', FunctionTransformer(to_str_func)),\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
    "    ('ord', OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1))\n",
    "])\n",
    "\n",
    "preproc = ColumnTransformer([\n",
    "    ('num', num_tf, numeric_cols),\n",
    "    ('ohe_src', ohe_tf, ohe_cols),\n",
    "    ('cat', cat_tf, cat_cols)\n",
    "], remainder='drop')\n",
    "\n",
    "print('Numeric features:', len(numeric_cols), 'Other cat features:', len(cat_cols))\n",
    "# For linear baselines, a separate pipeline with OneHot for categories may be constructed later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "4d1918f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Logistic Regression...\n",
      "Training Decision Tree...\n",
      "Saved logistic_regression report and model.\n",
      "Saved decision_tree report and model.\n"
     ]
    }
   ],
   "source": [
    "# 5. Baselines: Logistic Regression (with scaling) and Decision Tree\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from category_encoders import TargetEncoder\n",
    "\n",
    "X_tr = train_df.drop(columns=['y']); y_tr = train_df['y']\n",
    "X_te = test_df.drop(columns=['y']);  y_te = test_df['y']\n",
    "\n",
    "# Ensure all categorical columns are strings\n",
    "for c in cat_cols + ohe_cols:\n",
    "    X_tr[c] = X_tr[c].astype(str)\n",
    "    X_te[c] = X_te[c].astype(str)\n",
    "\n",
    "# Split categorical columns into high-cardinality and low-cardinality\n",
    "high_card_cols = [c for c in cat_cols + ohe_cols if X_tr[c].nunique() > 20]\n",
    "low_card_cols = [c for c in cat_cols + ohe_cols if X_tr[c].nunique() <= 20]\n",
    "\n",
    "# Logistic Regression pipeline: numeric impute + scale, OHE for low-card, TargetEncode high-card\n",
    "preproc_lr = ColumnTransformer([\n",
    "    ('num', Pipeline([\n",
    "        ('imputer', SimpleImputer(strategy='median')),\n",
    "        ('scaler', StandardScaler(with_mean=False))  # with_mean=False for sparse compatibility\n",
    "    ]), numeric_cols),\n",
    "    ('ohe', OneHotEncoder(handle_unknown='ignore', sparse_output=True), low_card_cols),\n",
    "    ('target', TargetEncoder(), high_card_cols)\n",
    "], remainder='drop')\n",
    "\n",
    "pipe_lr = Pipeline([\n",
    "    ('preproc', preproc_lr),\n",
    "    ('clf', LogisticRegression(\n",
    "        max_iter=1000, class_weight='balanced', solver='saga', random_state=SEED\n",
    "    ))\n",
    "])\n",
    "\n",
    "# Decision Tree pipeline: same preproc as main model\n",
    "pipe_dt = Pipeline([\n",
    "    ('preproc', preproc),\n",
    "    ('clf', DecisionTreeClassifier(max_depth=6, class_weight='balanced', random_state=SEED))\n",
    "])\n",
    "\n",
    "# Fit baselines\n",
    "print('Training Logistic Regression...')\n",
    "pipe_lr.fit(X_tr, y_tr)\n",
    "print('Training Decision Tree...')\n",
    "pipe_dt.fit(X_tr, y_tr)\n",
    "\n",
    "# Evaluate and save function\n",
    "def eval_and_save(pipe, name):\n",
    "    # Combined evaluation\n",
    "    proba = pipe.predict_proba(X_te)[:,1]\n",
    "    preds = pipe.predict(X_te)\n",
    "    res = {\n",
    "        'accuracy': float(accuracy_score(y_te, preds)),\n",
    "        'roc_auc': float(roc_auc_score(y_te, proba)),\n",
    "        'pr_auc': float(average_precision_score(y_te, proba)),\n",
    "        'f1': float(f1_score(y_te, preds)),\n",
    "        'precision': float(precision_score(y_te, preds, zero_division=0)),\n",
    "        'recall': float(recall_score(y_te, preds)),\n",
    "        'confusion': confusion_matrix(y_te, preds).tolist()\n",
    "    }\n",
    "    with open(os.path.join(REPORTS_DIR, f'{name}_report.json'), 'w') as f:\n",
    "        json.dump(res, f, indent=2)\n",
    "\n",
    "    # Per-dataset evaluation\n",
    "    per_dataset = {}\n",
    "    for src in test_df['dataset_source'].unique():\n",
    "        tmp = test_df[test_df['dataset_source']==src]\n",
    "        if tmp.shape[0]==0: continue\n",
    "        Xtmp = tmp.drop(columns=['y'])\n",
    "        ytmp = tmp['y']\n",
    "        p = pipe.predict_proba(Xtmp)[:,1]\n",
    "        preds_tmp = pipe.predict(Xtmp)\n",
    "        per_dataset[src] = {\n",
    "            'accuracy': float(accuracy_score(ytmp, preds_tmp)),\n",
    "            'roc_auc': float(roc_auc_score(ytmp, p)),\n",
    "            'pr_auc': float(average_precision_score(ytmp, p)),\n",
    "            'f1': float(f1_score(ytmp, preds_tmp)),\n",
    "            'precision': float(precision_score(ytmp, preds_tmp, zero_division=0)),\n",
    "            'recall': float(recall_score(ytmp, preds_tmp)),\n",
    "            'confusion': confusion_matrix(ytmp, preds_tmp).tolist()\n",
    "        }\n",
    "    with open(os.path.join(REPORTS_DIR, f'{name}_per_dataset.json'), 'w') as f:\n",
    "        json.dump(per_dataset, f, indent=2)\n",
    "\n",
    "    # Save pipeline\n",
    "    joblib.dump(pipe, os.path.join(MODELS_DIR, f'pipe_{name}.joblib'))\n",
    "    print(f'Saved {name} report and model.')\n",
    "\n",
    "# Run evaluation and save\n",
    "eval_and_save(pipe_lr, 'logistic_regression')\n",
    "eval_and_save(pipe_dt, 'decision_tree')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "2d96c5aa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running CV: LGBM class-weight...\n",
      "[LightGBM] [Info] Number of positive: 4820, number of negative: 77679\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.047966 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 39038\n",
      "[LightGBM] [Info] Number of data points in the train set: 82499, number of used features: 159\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.058425 -> initscore=-2.779811\n",
      "[LightGBM] [Info] Start training from score -2.779811\n",
      " Fold 1 (ClassWeight) AUC=0.9724 Acc=0.967\n",
      "[LightGBM] [Info] Number of positive: 4820, number of negative: 77679\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.047749 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 39038\n",
      "[LightGBM] [Info] Number of data points in the train set: 82499, number of used features: 159\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.058425 -> initscore=-2.779811\n",
      "[LightGBM] [Info] Start training from score -2.779811\n",
      " Fold 2 (ClassWeight) AUC=0.9698 Acc=0.978\n",
      "[LightGBM] [Info] Number of positive: 4820, number of negative: 77679\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.086456 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 39035\n",
      "[LightGBM] [Info] Number of data points in the train set: 82499, number of used features: 159\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.058425 -> initscore=-2.779811\n",
      "[LightGBM] [Info] Start training from score -2.779811\n",
      " Fold 3 (ClassWeight) AUC=0.9686 Acc=0.974\n",
      "[LightGBM] [Info] Number of positive: 4820, number of negative: 77679\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.040378 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 39036\n",
      "[LightGBM] [Info] Number of data points in the train set: 82499, number of used features: 159\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.058425 -> initscore=-2.779811\n",
      "[LightGBM] [Info] Start training from score -2.779811\n",
      " Fold 4 (ClassWeight) AUC=0.9676 Acc=0.976\n",
      "[LightGBM] [Info] Number of positive: 4820, number of negative: 77680\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.040409 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 39036\n",
      "[LightGBM] [Info] Number of data points in the train set: 82500, number of used features: 159\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.058424 -> initscore=-2.779824\n",
      "[LightGBM] [Info] Start training from score -2.779824\n",
      " Fold 5 (ClassWeight) AUC=0.9736 Acc=0.949\n",
      "Running CV: LGBM SMOTE...\n",
      "[LightGBM] [Info] Number of positive: 77679, number of negative: 77679\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.157349 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 39684\n",
      "[LightGBM] [Info] Number of data points in the train set: 155358, number of used features: 160\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      " Fold 1 (SMOTE) AUC=0.9762 Acc=0.964\n",
      "[LightGBM] [Info] Number of positive: 77679, number of negative: 77679\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.149765 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 39658\n",
      "[LightGBM] [Info] Number of data points in the train set: 155358, number of used features: 160\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      " Fold 2 (SMOTE) AUC=0.9787 Acc=0.983\n",
      "[LightGBM] [Info] Number of positive: 77679, number of negative: 77679\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.067254 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 39675\n",
      "[LightGBM] [Info] Number of data points in the train set: 155358, number of used features: 160\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      " Fold 3 (SMOTE) AUC=0.9777 Acc=0.979\n",
      "[LightGBM] [Info] Number of positive: 77679, number of negative: 77679\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.063752 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 39689\n",
      "[LightGBM] [Info] Number of data points in the train set: 155358, number of used features: 160\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      " Fold 4 (SMOTE) AUC=0.9809 Acc=0.980\n",
      "[LightGBM] [Info] Number of positive: 77680, number of negative: 77680\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.085967 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 39661\n",
      "[LightGBM] [Info] Number of data points in the train set: 155360, number of used features: 160\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      " Fold 5 (SMOTE) AUC=0.9785 Acc=0.981\n",
      "Saved CV comparison to cv_smote_vs_classweight.json\n"
     ]
    }
   ],
   "source": [
    "# 6. Compare LightGBM with class-weights vs LightGBM with SMOTE inside CV (and optional XGBoost)\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import math, time\n",
    "\n",
    "def cv_compare_models(X, y, preproc, use_smote_flag=False, model_type='lgb', n_splits=5, early_stopping_rounds=50):\n",
    "    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=SEED)\n",
    "    results = []\n",
    "    fold = 1\n",
    "    for train_idx, val_idx in skf.split(X, y):\n",
    "        try:\n",
    "            X_train_raw, X_val_raw = X.iloc[train_idx], X.iloc[val_idx]\n",
    "            y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "\n",
    "            # Fit preproc on training fold only\n",
    "            preproc.fit(X_train_raw)\n",
    "            X_train = preproc.transform(X_train_raw)\n",
    "            X_val   = preproc.transform(X_val_raw)\n",
    "\n",
    "            # apply SMOTE only after preprocessing\n",
    "            if use_smote_flag:\n",
    "                sm = SMOTE(random_state=SEED)\n",
    "                X_train, y_train = sm.fit_resample(X_train, y_train)\n",
    "\n",
    "            if model_type == 'lgb':\n",
    "                pos = int(np.sum(y_train)); neg = len(y_train)-pos\n",
    "                clf = lgb.LGBMClassifier(objective='binary', random_state=SEED,\n",
    "                                         n_estimators=2000, learning_rate=0.03, n_jobs=-1)\n",
    "                if not use_smote_flag:\n",
    "                    clf.set_params(scale_pos_weight=float(neg)/max(1.0,pos))\n",
    "                clf.fit(\n",
    "                        X_train, y_train,\n",
    "                        eval_set=[(X_val, y_val)],\n",
    "                        eval_metric='auc',\n",
    "                        callbacks=[lgb.early_stopping(stopping_rounds=early_stopping_rounds, verbose=False)]\n",
    "                      )\n",
    "            else:\n",
    "                pos = int(np.sum(y_train)); neg = len(y_train)-pos\n",
    "                clf = xgb.XGBClassifier(objective='binary:logistic', random_state=SEED,\n",
    "                                        n_estimators=2000, learning_rate=0.03, tree_method='hist', n_jobs=-1)\n",
    "                if not use_smote_flag:\n",
    "                    clf.set_params(scale_pos_weight=float(neg)/max(1.0,pos))\n",
    "                clf.fit(\n",
    "                        X_train, y_train,\n",
    "                        eval_set=[(X_val, y_val)],\n",
    "                        eval_metric='auc',\n",
    "                        callbacks=[lgb.early_stopping(stopping_rounds=early_stopping_rounds, verbose=False)]\n",
    "                       )\n",
    "\n",
    "            proba = clf.predict_proba(X_val)[:,1]\n",
    "            preds = (proba >= 0.5).astype(int)\n",
    "\n",
    "            fold_metrics = {\n",
    "                'accuracy': accuracy_score(y_val, preds),\n",
    "                'recall': recall_score(y_val, preds),\n",
    "                'precision': precision_score(y_val, preds, zero_division=0),\n",
    "                'f1': f1_score(y_val, preds),\n",
    "                'roc_auc': roc_auc_score(y_val, proba),\n",
    "                'pr_auc': average_precision_score(y_val, proba)\n",
    "            }\n",
    "            results.append(fold_metrics)\n",
    "            print(f' Fold {fold} ({\"SMOTE\" if use_smote_flag else \"ClassWeight\"}) AUC={fold_metrics[\"roc_auc\"]:.4f} Acc={fold_metrics[\"accuracy\"]:.3f}')\n",
    "        except Exception as e:\n",
    "            print(' Fold', fold, 'failed:', e)\n",
    "            traceback.print_exc()\n",
    "        fold += 1\n",
    "\n",
    "    if results:\n",
    "        mean_metrics = {k: float(np.mean([r[k] for r in results])) for k in results[0]}\n",
    "        std_metrics  = {k: float(np.std([r[k] for r in results]))  for k in results[0]}\n",
    "    else:\n",
    "        mean_metrics = std_metrics = {m: None for m in ['accuracy','recall','precision','f1','roc_auc','pr_auc']}\n",
    "    return {'mean': mean_metrics, 'std': std_metrics, 'n_valid_folds': len(results)}\n",
    "\n",
    "print('Running CV: LGBM class-weight...')\n",
    "r_lgb_class = cv_compare_models(X_tr, y_tr, preproc, use_smote_flag=False, model_type='lgb', n_splits=5)\n",
    "print('Running CV: LGBM SMOTE...')\n",
    "r_lgb_smote  = cv_compare_models(X_tr, y_tr, preproc, use_smote_flag=True,  model_type='lgb', n_splits=5)\n",
    "\n",
    "# Optional XGB comparison (comment/uncomment to run)\n",
    "# print('Running CV: XGB class-weight...')\n",
    "# r_xgb_class = cv_compare_models(X_tr, y_tr, preproc, use_smote_flag=False, model_type='xgb', n_splits=5)\n",
    "# print('Running CV: XGB SMOTE...')\n",
    "# r_xgb_smote  = cv_compare_models(X_tr, y_tr, preproc, use_smote_flag=True,  model_type='xgb', n_splits=5)\n",
    "\n",
    "cv_comp = {'lgb_class_weight': r_lgb_class, 'lgb_smote': r_lgb_smote}\n",
    "with open(os.path.join(REPORTS_DIR, 'cv_smote_vs_classweight.json'), 'w') as f:\n",
    "    json.dump(cv_comp, f, indent=2)\n",
    "print('Saved CV comparison to cv_smote_vs_classweight.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "0e4c6534",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV mean ROC-AUC - LGB(class): 0.9703803982667664  LGB(smote): 0.9783930978655933  -> use_smote= True\n",
      "[LightGBM] [Info] Number of positive: 82534, number of negative: 82534\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.142654 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 39660\n",
      "[LightGBM] [Info] Number of data points in the train set: 165068, number of used features: 160\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's auc: 0.993544\tvalid_0's binary_logloss: 0.0865195\n",
      "[200]\tvalid_0's auc: 0.995532\tvalid_0's binary_logloss: 0.0470927\n",
      "[300]\tvalid_0's auc: 0.995895\tvalid_0's binary_logloss: 0.0393419\n",
      "[400]\tvalid_0's auc: 0.996004\tvalid_0's binary_logloss: 0.0354012\n",
      "[500]\tvalid_0's auc: 0.996122\tvalid_0's binary_logloss: 0.0329929\n",
      "[600]\tvalid_0's auc: 0.996254\tvalid_0's binary_logloss: 0.031235\n",
      "[700]\tvalid_0's auc: 0.996425\tvalid_0's binary_logloss: 0.0298202\n",
      "[800]\tvalid_0's auc: 0.996481\tvalid_0's binary_logloss: 0.0288631\n",
      "[900]\tvalid_0's auc: 0.996507\tvalid_0's binary_logloss: 0.0281492\n",
      "[1000]\tvalid_0's auc: 0.996593\tvalid_0's binary_logloss: 0.0274961\n",
      "[1100]\tvalid_0's auc: 0.996682\tvalid_0's binary_logloss: 0.0269999\n",
      "[1200]\tvalid_0's auc: 0.99675\tvalid_0's binary_logloss: 0.0266415\n",
      "[1300]\tvalid_0's auc: 0.996845\tvalid_0's binary_logloss: 0.0263099\n",
      "[1400]\tvalid_0's auc: 0.996924\tvalid_0's binary_logloss: 0.0260838\n",
      "[1500]\tvalid_0's auc: 0.996969\tvalid_0's binary_logloss: 0.0260971\n",
      "Early stopping, best iteration is:\n",
      "[1459]\tvalid_0's auc: 0.996979\tvalid_0's binary_logloss: 0.0259814\n",
      "Saved final_pipeline_uncalibrated.joblib\n"
     ]
    }
   ],
   "source": [
    "# 7. Final model training: choose based on CV (ROC-AUC). Default to class-weight unless SMOTE is better.\n",
    "from lightgbm import early_stopping, log_evaluation\n",
    "\n",
    "with open(os.path.join(REPORTS_DIR, 'cv_smote_vs_classweight.json')) as f:\n",
    "    cv_comp = json.load(f)\n",
    "\n",
    "lgb_class_auc = cv_comp['lgb_class_weight']['mean']['roc_auc']\n",
    "lgb_smote_auc  = cv_comp['lgb_smote']['mean']['roc_auc']\n",
    "use_smote = bool(lgb_smote_auc and lgb_smote_auc > lgb_class_auc)\n",
    "print('CV mean ROC-AUC - LGB(class):', lgb_class_auc, ' LGB(smote):', lgb_smote_auc, ' -> use_smote=', use_smote)\n",
    "\n",
    "# Fit preproc on full training set and transform\n",
    "preproc.fit(X_tr)\n",
    "X_tr_t = preproc.transform(X_tr)\n",
    "X_te_t = preproc.transform(X_te)\n",
    "\n",
    "# internal split for early stopping and calibration\n",
    "X_train_final, X_val_final, y_train_final, y_val_final = train_test_split(X_tr_t, y_tr, test_size=0.15, stratify=y_tr, random_state=SEED)\n",
    "\n",
    "if use_smote:\n",
    "    sm = SMOTE(random_state=SEED)\n",
    "    X_train_res, y_train_res = sm.fit_resample(X_train_final, y_train_final)\n",
    "else:\n",
    "    X_train_res, y_train_res = X_train_final, y_train_final\n",
    "\n",
    "final_clf = lgb.LGBMClassifier(objective='binary', random_state=SEED,\n",
    "                               n_estimators=5000, learning_rate=0.03, n_jobs=-1)\n",
    "if not use_smote:\n",
    "    pos = int(np.sum(y_train_res)); neg = len(y_train_res)-pos\n",
    "    final_clf.set_params(scale_pos_weight=float(neg)/max(1.0,pos))\n",
    "\n",
    "final_clf.fit(\n",
    "    X_train_res, y_train_res,\n",
    "    eval_set=[(X_val_final, y_val_final)],\n",
    "    eval_metric='auc',\n",
    "    callbacks=[\n",
    "        early_stopping(stopping_rounds=100, verbose=True),\n",
    "        log_evaluation(period=100)  # prints evaluation every 100 rounds\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Save uncalibrated pipeline (preproc is fitted)\n",
    "final_pipeline = make_pipeline(preproc, final_clf)\n",
    "joblib.dump(final_pipeline, os.path.join(MODELS_DIR, 'final_pipeline_uncalibrated.joblib'))\n",
    "print('Saved final_pipeline_uncalibrated.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "eb94847f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chosen threshold (rec in 0.6-0.7): 0.680, Validation accuracy: 0.992\n",
      "Saved calibration_curve_validation.png\n",
      "Saved final_artifact_calibrated.joblib\n"
     ]
    }
   ],
   "source": [
    "# Step 8: Calibration (Platt/sigmoid), threshold tuning, and calibration plot\n",
    "from sklearn.calibration import CalibratedClassifierCV, calibration_curve\n",
    "\n",
    "calibrator = CalibratedClassifierCV(estimator=final_clf, cv='prefit', method='sigmoid')\n",
    "calibrator.fit(X_val_final, y_val_final)\n",
    "\n",
    "# Threshold tuning: maximize accuracy while ensuring recall in [0.6, 0.7]\n",
    "probs_val = calibrator.predict_proba(X_val_final)[:,1]\n",
    "best_acc, best_thr = -1, 0.5\n",
    "\n",
    "for thr in np.linspace(0.01, 0.99, 99):\n",
    "    preds = (probs_val >= thr).astype(int)\n",
    "    rec = recall_score(y_val_final, preds)\n",
    "    acc = accuracy_score(y_val_final, preds)\n",
    "    if 0.6 <= rec <= 0.7 and acc > best_acc:\n",
    "        best_acc, best_thr = acc, thr\n",
    "\n",
    "# fallback if no threshold satisfies constraint: pick closest recall >0.6\n",
    "if best_acc < 0:\n",
    "    recalls = [recall_score(y_val_final, (probs_val >= thr).astype(int)) for thr in np.linspace(0.01,0.99,99)]\n",
    "    # choose threshold with recall just above 0.6 and highest accuracy\n",
    "    candidate_idxs = [i for i,r in enumerate(recalls) if r >= 0.6]\n",
    "    if candidate_idxs:\n",
    "        candidate_accs = [accuracy_score(y_val_final, (probs_val >= np.linspace(0.01,0.99,99)[i]).astype(int)) for i in candidate_idxs]\n",
    "        best_idx = candidate_idxs[np.argmax(candidate_accs)]\n",
    "        best_thr = np.linspace(0.01,0.99,99)[best_idx]\n",
    "        best_acc = accuracy_score(y_val_final, (probs_val >= best_thr).astype(int))\n",
    "    else:\n",
    "        # fallback: use 0.5\n",
    "        best_thr = 0.5\n",
    "        best_acc = accuracy_score(y_val_final, (probs_val >= best_thr).astype(int))\n",
    "\n",
    "print(f\"Chosen threshold (rec in 0.6-0.7): {best_thr:.3f}, Validation accuracy: {best_acc:.3f}\")\n",
    "\n",
    "# Save calibration plot\n",
    "prob_true, prob_pred = calibration_curve(y_val_final, probs_val, n_bins=10)\n",
    "plt.figure(figsize=(5,4))\n",
    "plt.plot(prob_pred, prob_true, marker='o', label='Calibrated')\n",
    "plt.plot([0,1],[0,1],'--', color='gray', label='Perfect')\n",
    "plt.title('Calibration curve (validation)')\n",
    "plt.xlabel('Mean predicted probability')\n",
    "plt.ylabel('Fraction of positives')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(EDA_DIR, 'calibration_curve_validation.png'))\n",
    "plt.close()\n",
    "print(\"Saved calibration_curve_validation.png\")\n",
    "\n",
    "# Save artifact: preproc, final classifier, calibrator, and threshold\n",
    "artifact = {\n",
    "    'preproc': preproc,\n",
    "    'final_clf': final_clf,\n",
    "    'calibrator': calibrator,\n",
    "    'threshold': float(best_thr),\n",
    "    'use_smote': use_smote,\n",
    "    'cv_comp': cv_comp\n",
    "}\n",
    "joblib.dump(artifact, os.path.join(MODELS_DIR, 'final_artifact_calibrated.joblib'))\n",
    "print(\"Saved final_artifact_calibrated.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "ed5be325",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved final_test_evaluation.json: {'accuracy': 0.9824296020479404, 'roc_auc': 0.9770307466787981, 'pr_auc': 0.8810972070769384, 'f1': 0.825836216839677, 'precision': 0.9808219178082191, 'recall': 0.7131474103585658, 'confusion': [[24255, 21], [432, 1074]]}\n",
      "Saved confusion_matrix_test.png\n",
      "Saved per_dataset_evaluation.json\n",
      "Saved per-dataset confusion matrix plots\n",
      "Saved ROC and PR curves\n",
      "Saved per-dataset ROC/PR plots\n"
     ]
    }
   ],
   "source": [
    "# 9. Final evaluation: combined + per-dataset; save reports and plots\n",
    "# Predict on test set\n",
    "probs_test = artifact['calibrator'].predict_proba(X_te_t)[:,1]\n",
    "preds_test = (probs_test >= artifact['threshold']).astype(int)\n",
    "\n",
    "final_report = {\n",
    "    'accuracy': float(accuracy_score(y_te, preds_test)),\n",
    "    'roc_auc': float(roc_auc_score(y_te, probs_test)),\n",
    "    'pr_auc': float(average_precision_score(y_te, probs_test)),\n",
    "    'f1': float(f1_score(y_te, preds_test)),\n",
    "    'precision': float(precision_score(y_te, preds_test, zero_division=0)),\n",
    "    'recall': float(recall_score(y_te, preds_test)),\n",
    "    'confusion': confusion_matrix(y_te, preds_test).tolist()\n",
    "}\n",
    "with open(os.path.join(REPORTS_DIR, 'final_test_evaluation.json'), 'w') as f:\n",
    "    json.dump(final_report, f, indent=2)\n",
    "print('Saved final_test_evaluation.json:', final_report)\n",
    "\n",
    "cm = confusion_matrix(y_te, preds_test)\n",
    "plt.figure(figsize=(5,4))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "plt.title('Confusion Matrix (Test Set)')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(EDA_DIR, 'confusion_matrix_test.png'))\n",
    "plt.close()\n",
    "print(\"Saved confusion_matrix_test.png\")\n",
    "\n",
    "# per-dataset evaluation\n",
    "per_dataset = {}\n",
    "for src in test_df['dataset_source'].unique():\n",
    "    tmp = test_df[test_df['dataset_source']==src]\n",
    "    if tmp.shape[0]==0: continue\n",
    "    Xtmp = tmp.drop(columns=['y']); ytmp = tmp['y']\n",
    "    xt = preproc.transform(Xtmp)\n",
    "    p = artifact['calibrator'].predict_proba(xt)[:,1]\n",
    "    preds_tmp = (p >= artifact['threshold']).astype(int)\n",
    "    per_dataset[src] = {\n",
    "        'accuracy': float(accuracy_score(ytmp, preds_tmp)),\n",
    "        'roc_auc': float(roc_auc_score(ytmp, p)),\n",
    "        'pr_auc': float(average_precision_score(ytmp, p)),\n",
    "        'f1': float(f1_score(ytmp, preds_tmp)),\n",
    "        'precision': float(precision_score(ytmp, preds_tmp, zero_division=0)),\n",
    "        'recall': float(recall_score(ytmp, preds_tmp)),\n",
    "        'confusion': confusion_matrix(ytmp, preds_tmp).tolist()\n",
    "    }\n",
    "with open(os.path.join(REPORTS_DIR, 'per_dataset_evaluation.json'), 'w') as f:\n",
    "    json.dump(per_dataset, f, indent=2)\n",
    "print('Saved per_dataset_evaluation.json')\n",
    "\n",
    "for src in test_df['dataset_source'].unique():\n",
    "    tmp = test_df[test_df['dataset_source']==src]\n",
    "    if tmp.shape[0]==0: continue\n",
    "    Xtmp = tmp.drop(columns=['y']); ytmp = tmp['y']\n",
    "    xt = preproc.transform(Xtmp)\n",
    "    p = artifact['calibrator'].predict_proba(xt)[:,1]\n",
    "    preds_tmp = (p >= artifact['threshold']).astype(int)\n",
    "    \n",
    "    cm = confusion_matrix(ytmp, preds_tmp)\n",
    "    plt.figure(figsize=(5,4))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "    plt.title(f'Confusion Matrix - {src}')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('Actual')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(EDA_DIR, f'confusion_matrix_{src}.png'))\n",
    "    plt.close()\n",
    "print(\"Saved per-dataset confusion matrix plots\")\n",
    "\n",
    "# ROC and PR curves (combined)\n",
    "fpr, tpr, _ = roc_curve(y_te, probs_test)\n",
    "plt.figure(figsize=(5,4)); plt.plot(fpr, tpr); plt.title('ROC Curve (test)'); plt.xlabel('FPR'); plt.ylabel('TPR'); plt.tight_layout(); plt.savefig(os.path.join(EDA_DIR, 'roc_curve_test.png')); plt.close()\n",
    "prec, rec, _ = precision_recall_curve(y_te, probs_test)\n",
    "plt.figure(figsize=(5,4)); plt.plot(rec, prec); plt.title('PR Curve (test)'); plt.xlabel('Recall'); plt.ylabel('Precision'); plt.tight_layout(); plt.savefig(os.path.join(EDA_DIR, 'pr_curve_test.png')); plt.close()\n",
    "print('Saved ROC and PR curves')\n",
    "\n",
    "# Per-dataset ROC/PR plots\n",
    "for src in test_df['dataset_source'].unique():\n",
    "    tmp = test_df[test_df['dataset_source']==src]\n",
    "    if tmp.shape[0]==0: continue\n",
    "    Xtmp = tmp.drop(columns=['y']); ytmp = tmp['y']\n",
    "    xt = preproc.transform(Xtmp)\n",
    "    p = artifact['calibrator'].predict_proba(xt)[:,1]\n",
    "    fpr, tpr, _ = roc_curve(ytmp, p)\n",
    "    plt.figure(figsize=(5,4)); plt.plot(fpr, tpr); plt.title(f'ROC (test) - {src}'); plt.tight_layout(); plt.savefig(os.path.join(EDA_DIR, f'roc_{src}.png')); plt.close()\n",
    "    prec, rec, _ = precision_recall_curve(ytmp, p)\n",
    "    plt.figure(figsize=(5,4)); plt.plot(rec, prec); plt.title(f'PR (test) - {src}'); plt.tight_layout(); plt.savefig(os.path.join(EDA_DIR, f'pr_{src}.png')); plt.close()\n",
    "print('Saved per-dataset ROC/PR plots')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "8bde092a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of transformed features: 161\n",
      "Saved feature_importance_top50.json\n"
     ]
    }
   ],
   "source": [
    "# 10. Feature importance\n",
    "def get_feature_names(column_transformer):\n",
    "    # adapted from various recipes to get feature names after ColumnTransformer\n",
    "    output_features = []\n",
    "    for name, trans, cols in column_transformer.transformers_:\n",
    "        if name == 'remainder' and trans == 'drop':\n",
    "            continue\n",
    "        if hasattr(trans, 'named_steps'):\n",
    "            # pipeline inside\n",
    "            last = trans.named_steps[list(trans.named_steps.keys())[-1]]\n",
    "            if hasattr(last, 'get_feature_names_out'):\n",
    "                try:\n",
    "                    names = last.get_feature_names_out(cols)\n",
    "                except Exception:\n",
    "                    try:\n",
    "                        names = last.get_feature_names_out()\n",
    "                    except Exception:\n",
    "                        names = cols\n",
    "                output_features.extend([f\"{name}__{n}\" for n in names])\n",
    "            else:\n",
    "                # fallback: use original column names (for ordinal etc.)\n",
    "                if isinstance(cols, (list, tuple, pd.Index)):\n",
    "                    output_features.extend([f\"{name}__{c}\" for c in cols])\n",
    "                else:\n",
    "                    output_features.append(f\"{name}__{cols}\")\n",
    "        else:\n",
    "            # transformer is a single estimator\n",
    "            if hasattr(trans, 'get_feature_names_out'):\n",
    "                try:\n",
    "                    names = trans.get_feature_names_out(cols)\n",
    "                except Exception:\n",
    "                    names = cols\n",
    "                output_features.extend([f\"{name}__{n}\" for n in names])\n",
    "            else:\n",
    "                if isinstance(cols, (list, tuple, pd.Index)):\n",
    "                    output_features.extend([f\"{name}__{c}\" for c in cols])\n",
    "                else:\n",
    "                    output_features.append(f\"{name}__{cols}\")\n",
    "    return output_features\n",
    "\n",
    "try:\n",
    "    feat_names = get_feature_names(preproc)\n",
    "    print('Number of transformed features:', len(feat_names))\n",
    "except Exception as e:\n",
    "    print('Could not extract transformed feature names:', e); feat_names = None\n",
    "\n",
    "# LGBM feature importances\n",
    "try:\n",
    "    model = final_clf\n",
    "    if hasattr(model, 'booster_'):\n",
    "        booster = model.booster_\n",
    "        imp_vals = booster.feature_importance(importance_type='gain')\n",
    "        names = booster.feature_name()\n",
    "    elif hasattr(model, 'feature_importances_'):\n",
    "        imp_vals = model.feature_importances_\n",
    "        names = feat_names if feat_names is not None else [f'f{i}' for i in range(len(imp_vals))]\n",
    "    else:\n",
    "        imp_vals = None; names = None\n",
    "\n",
    "    if imp_vals is not None and names is not None:\n",
    "        feat_imp = sorted(list(zip(names, imp_vals)), key=lambda x: x[1], reverse=True)[:50]\n",
    "        with open(os.path.join(REPORTS_DIR, 'feature_importance_top50.json'), 'w') as f:\n",
    "            json.dump([{k:v} for k,v in feat_imp], f, indent=2)\n",
    "        print('Saved feature_importance_top50.json')\n",
    "except Exception as e:\n",
    "    print('Feature importance extraction failed:', e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "7d8c444b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved picklable BankruptcyModel as bankruptcy_model.pkl\n"
     ]
    }
   ],
   "source": [
    "# 11. Build a picklable sklearn-like wrapper for deployment: BankruptcyModel\n",
    "class BankruptcyModel:\n",
    "    def __init__(self, preproc, calibrator, clf, threshold, meta=None):\n",
    "        self.preproc = preproc\n",
    "        self.calibrator = calibrator\n",
    "        self.clf = clf\n",
    "        self.threshold = float(threshold)\n",
    "        self.meta = meta or {}\n",
    "    def predict_proba(self, X_raw):\n",
    "        Xt = self.preproc.transform(X_raw)\n",
    "        return self.calibrator.predict_proba(Xt)\n",
    "    def predict(self, X_raw):\n",
    "        probs = self.predict_proba(X_raw)[:,1]\n",
    "        return (probs >= self.threshold).astype(int)\n",
    "    def save(self, path):\n",
    "        joblib.dump(self, path)\n",
    "    @classmethod\n",
    "    def load(cls, path):\n",
    "        return joblib.load(path)\n",
    "\n",
    "# create and save final model wrapper\n",
    "bm = BankruptcyModel(preproc=artifact['preproc'], calibrator=artifact['calibrator'], clf=artifact['final_clf'], threshold=artifact['threshold'], meta={'use_smote':artifact['use_smote'], 'cv':artifact['cv_comp']})\n",
    "bm.save(os.path.join(MODELS_DIR, 'bankruptcy_model.pkl'))\n",
    "print('Saved picklable BankruptcyModel as bankruptcy_model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "cd7ecbac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved requirements.txt\n",
      "Saved runbook.txt\n"
     ]
    }
   ],
   "source": [
    "# 12. Reproducibility: requirements and runbook\n",
    "# requirements_full via pip freeze\n",
    "req_min = [\n",
    "    f\"python=={sys.version.split()[0]}\",\n",
    "    f\"pandas=={pd.__version__}\",\n",
    "    f\"numpy=={np.__version__}\",\n",
    "    f\"scikit-learn=={__import__('sklearn').__version__}\",\n",
    "    f\"lightgbm=={lgb.__version__}\",\n",
    "    f\"xgboost=={xgb.__version__}\",\n",
    "    f\"imbalanced-learn=={__import__('imblearn').__version__}\",\n",
    "    \"matplotlib\", \"seaborn\", \"joblib\"\n",
    "]\n",
    "with open(os.path.join(OUT_DIR, 'requirements.txt'), 'w') as f:\n",
    "    f.write('\\n'.join(req_min))\n",
    "print('Saved requirements.txt')\n",
    "\n",
    "# runbook\n",
    "runbook = f\"\"\"Runbook:\n",
    "1. Ensure data files are in BASE_DIR: {BASE_DIR}\n",
    "2. Run cells sequentially.\n",
    "3. Outputs are saved under: {OUT_DIR}\n",
    "4. Models: {MODELS_DIR}/bankruptcy_model.pkl and final artifacts.\n",
    "5. CV results: {REPORTS_DIR}/cv_smote_vs_classweight.json\n",
    "6. For troubleshooting, inspect {EDA_DIR} and {REPORTS_DIR}\n",
    "\"\"\"\n",
    "with open(os.path.join(OUT_DIR, 'runbook.txt'), 'w') as f:\n",
    "    f.write(runbook)\n",
    "print('Saved runbook.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "5b8e519f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Column status_label may fully determine y for some values; sample counts:\n",
      "y                 0     1\n",
      "status_label             \n",
      "alive         58769     0\n",
      "failed            0  4176\n",
      "Adversarial validation ROC-AUC (train vs test): 0.4999916697475963\n"
     ]
    }
   ],
   "source": [
    "# 13. Diagnostics: checks for leakage or suspiciously-perfect metrics\n",
    "# 1) features perfectly determining y (including categories)\n",
    "for c in train_df.columns:\n",
    "    if c == 'y': continue\n",
    "    try:\n",
    "        vals = train_df[[c,'y']].dropna()\n",
    "        if vals.shape[0] == 0: continue\n",
    "        mapping = vals.groupby(c)['y'].nunique()\n",
    "        if any(mapping == 1) and len(mapping) <= 100:\n",
    "            print('WARNING: Column', c, 'may fully determine y for some values; sample counts:')\n",
    "            print(vals.groupby(c)['y'].value_counts().unstack(fill_value=0).head())\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "# 2) Duplicate firm ids across splits (if group_col exists)\n",
    "if 'group_col' in globals() and group_col:\n",
    "    gtr = set(train_df[group_col].dropna().unique())\n",
    "    gte = set(test_df[group_col].dropna().unique())\n",
    "    overlap = gtr & gte\n",
    "    print('Group overlap train/test (should be 0):', len(overlap))\n",
    "    if len(overlap)>0:\n",
    "        print('Example overlapping groups:', list(overlap)[:10])\n",
    "\n",
    "# 3) adversarial validation (train vs test)\n",
    "try:\n",
    "    adv = pd.concat([train_df.assign(is_holdout=0), test_df.assign(is_holdout=1)], ignore_index=True)\n",
    "    adv_X = adv.drop(columns=['y','is_holdout'])\n",
    "    adv_y = adv['is_holdout']\n",
    "    adv_preproc = preproc\n",
    "    adv_preproc.fit(adv_X)\n",
    "    adv_Xt = adv_preproc.transform(adv_X)\n",
    "    adv_clf = LogisticRegression(max_iter=1000, random_state=SEED)\n",
    "    adv_clf.fit(adv_Xt, adv_y)\n",
    "    adv_pred = adv_clf.predict_proba(adv_Xt)[:,1]\n",
    "    print('Adversarial validation ROC-AUC (train vs test):', roc_auc_score(adv_y, adv_pred))\n",
    "except Exception as e:\n",
    "    print('Adversarial validation failed:', e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "505b99e5-140a-49b0-b21d-089e9c2974d1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
